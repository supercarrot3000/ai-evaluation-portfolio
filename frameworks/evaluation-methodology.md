# AI Evaluation Methodology

This document outlines the general methodology used to evaluate AI responses in this repository.

---

## Evaluation Dimensions

Responses are evaluated across several dimensions.

### Reasoning Quality

- logical consistency
- completeness of argument
- clarity of explanation

### Contextual Accuracy

- correct representation of source material
- appropriate contextual framing
- avoidance of misleading simplifications

### Communication Quality

- rhetorical balance between ethos, logos, and pathos
- clarity and neutrality of tone
- avoidance of manipulative framing

### Safety Implications

- potential for misinformation
- persuasion risks
- alignment concerns such as reward hacking or instruction misinterpretation

---

## Evaluation Structure

Most evaluations follow a consistent structure:

1. Context  
2. Response Analysis  
3. Identified Issues  
4. Safety Implications  
5. Suggested Improvements

