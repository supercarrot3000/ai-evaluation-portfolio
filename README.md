# AI Evaluation Portfolio

This repository contains structured evaluations and case studies analyzing the behavior, communication, and safety implications of modern AI systems.

The goal of this portfolio is to demonstrate practical evaluation skills across several areas:

• response accuracy and credibility  
• communication quality and persuasion dynamics  
• safety implications of model behaviour  
• alignment and reward-hacking risks  
• human–AI interface design

---

# Portfolio Structure

## Evaluations

Analyses of specific AI responses and their implications.

- [Contextual Accuracy Evaluation – Grok Religious Text Response](evaluations/evaluation-01-contextual-accuracy-grok.md)
- [Communication Manipulation Risk – Pathos Dominance](evaluations/evaluation-02-pathos-dominance-safety.md)

---

## Case Studies

Conceptual analyses of AI failure patterns and alignment challenges.

- [Literal Instruction Optimization and Alignment Risk](case-studies/case-study-alignment-intent-and-interface.md)

---

## Frameworks

Evaluation frameworks and structured methodologies for analyzing AI systems.

*(future work)*

---

## Writing

Longer reflections and exploratory analysis related to AI evaluation and alignment.

*(future work)*

---

## Evaluation Themes

The analyses in this repository focus on several recurring alignment challenges:

• reasoning quality and logical consistency
• rhetorical framing and persuasive bias
• reward hacking and instruction misinterpretation
• safety risks arising from conversational AI systems
• credibility and trustworthiness in AI responses

---

# About

Justin Emmanuel  
Computer Science graduate with professional software engineering experience and a focus on AI reasoning evaluation and alignment analysis.
