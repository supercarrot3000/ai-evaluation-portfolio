# AI Evaluation Portfolio

This repository contains structured evaluations and case studies analyzing the behavior, communication, and safety implications of modern AI systems.

The goal of this portfolio is to demonstrate practical evaluation skills across several areas:

• response accuracy and credibility  
• communication quality and persuasion dynamics  
• safety implications of model behaviour  
• alignment and reward-hacking risks  
• human–AI interface design

---

# Portfolio Structure

## Evaluations

Analyses of specific AI responses and their implications.

- [Contextual Accuracy Evaluation – Grok Religious Text Response](evaluations/evaluation-01-contextual-accuracy-grok.md)
- [Communication Manipulation Risk – Pathos Dominance](evaluations/evaluation-02-pathos-dominance-safety.md)

---

## Case Studies

Conceptual analyses of AI failure patterns and alignment challenges.

- [Literal Instruction Optimization and Alignment Risk](case-studies/case-study-alignment-intent-and-interface.md)

---

## Frameworks

Evaluation frameworks and structured methodologies for analyzing AI systems.

*(future work)*

---

## Writing

Longer reflections and exploratory analysis related to AI evaluation and alignment.

*(future work)*

---

# Focus Areas

This portfolio focuses on several evaluation themes:

• alignment and specification gaming  
• credibility and information accuracy  
• persuasion dynamics in AI communication  
• safety implications of model behavior  
• expectation calibration in human–AI interfaces
